## Day 3:

Topics cover
Optimizers
- Gradient Descent
- SAD ( Stochastic Gradient Descent )
- Mini Batch SAD
- SGD with Momentum
- Adagrad
- RMSProp
- Adam
